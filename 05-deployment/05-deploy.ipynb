{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2dc2fed-2cc9-4bf3-8adb-274c184d8061",
   "metadata": {},
   "source": [
    "# 5. Deploying Machine Learning models \n",
    "\n",
    "We'll use the same model we trained and evaluated previously - the churn prediction model. Now we'll deploy it as a web service.\n",
    "\n",
    "## 5.1 Intro / Session overview\n",
    "We need to put the model that lives in our Jupyter Notebook into production, so other services can use the model to make decisions based on the output of our model.\n",
    "\n",
    "Suppose we have a service for running marketing campaigns. For each customer, it needs to determine the probability of churn, and if it's high enough, it will send a promotional email with discounts. This service needs to use our model to decide whether it should send an email. \n",
    "\n",
    "What we will cover this week: \n",
    "* Saving models with Pickle\n",
    "* Serving models with Flask\n",
    "* Managing dependencies with Pipenv\n",
    "* Making the service self-contained with Docker\n",
    "* Deploying it to the cloud using AWS Elastic Beanstalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ff7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b9c8d1-3b63-4fc2-828c-7878dd6e9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-03-churn-prediction/WA_Fn-UseC_-Telco-Customer-Churn.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ee3ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data-week-3.csv')\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "\n",
    "for c in categorical_columns:\n",
    "    df[c] = df[c].str.lower().str.replace(' ', '_')\n",
    "\n",
    "df.totalcharges = pd.to_numeric(df.totalcharges, errors='coerce')\n",
    "df.totalcharges = df.totalcharges.fillna(0)\n",
    "\n",
    "df.churn = (df.churn == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b1903b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4132a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "\n",
    "categorical = [\n",
    "    'gender',\n",
    "    'seniorcitizen',\n",
    "    'partner',\n",
    "    'dependents',\n",
    "    'phoneservice',\n",
    "    'multiplelines',\n",
    "    'internetservice',\n",
    "    'onlinesecurity',\n",
    "    'onlinebackup',\n",
    "    'deviceprotection',\n",
    "    'techsupport',\n",
    "    'streamingtv',\n",
    "    'streamingmovies',\n",
    "    'contract',\n",
    "    'paperlessbilling',\n",
    "    'paymentmethod',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92708443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(C=C, max_iter=3000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ac302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b01b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.0\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce936aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0 0.842 +- 0.007\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train.churn.values\n",
    "    y_val = df_val.churn.values\n",
    "\n",
    "    dv, model = train(df_train, y_train, C=C)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "\n",
    "print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f72b194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.8443806862337213),\n",
       " np.float64(0.8449563799496754),\n",
       " np.float64(0.83351796106763),\n",
       " np.float64(0.8347649005563726),\n",
       " np.float64(0.8517892441404411)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03e81326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8583598751990639)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model = train(df_full_train, df_full_train.churn.values, C=1.0)\n",
    "y_pred = predict(df_test, dv, model)\n",
    "\n",
    "y_test = df_test.churn.values\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f0681-8cd1-4da2-9736-17579c797fcf",
   "metadata": {},
   "source": [
    "## 5.2 Saving and loading the model\n",
    "\n",
    "* Saving the model to pickle\n",
    "* Loading the model from pickle\n",
    "* Turning our notebook into a Python script\n",
    "\n",
    "To be able to use it outside of our notebook, we need to save it, and then later, another process can load and use it.\n",
    "\n",
    "Pickle is a serialization/deserialization module that's already built into Python: using it, we can save an arbitrary Python object (with a few exceptions) to a file. Once we have a file, we can load the model from there in a different process.\n",
    "\n",
    "Install the library with the command `pip install pickle-mixin` if you don't have it.\n",
    "\n",
    "To save the model, we first import the `pickle` module, and then use the `dump` function:\n",
    "  ```python\n",
    "  import pickle\n",
    "\n",
    "  with open('model.bin', 'wb') as f_out:  # 'wb' means write binary\n",
    "      pickle.dump((dict_vectorizer, model), f_out)\n",
    "  ```\n",
    "  \n",
    "To use the model, we need to open the binary file we saved and load the model using the `load` function.\n",
    "\n",
    "  ```python\n",
    "  import pickle\n",
    "\n",
    "  with open('model.bin', 'rb') as f_in:  # 'rb' means read binary\n",
    "      # Note: Never open a binary file from an untrusted source!\n",
    "      dict_vectorizer, model = pickle.load(f_in)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e8c00a-1a6c-4a35-9c18-062991be2eba",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a452f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4d16a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f'model_C={C}.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9533d28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_C=1.0.bin'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f07f38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to the file in binary\n",
    "f_out = open(output_file, 'wb') \n",
    "pickle.dump((dv, model), f_out)\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8887621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lh *.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f85192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'wb') as f_out: \n",
    "    pickle.dump((dv, model), f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d8a59e",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fe3b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "007e9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'model_C=1.0.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b876b1ab-0e07-48ba-95a2-c057398cdd3a",
   "metadata": {},
   "source": [
    "Be careful when specifying the mode. Accidentally specifying an incorrect mode may result in data loss: if you open an existing file with the `w` mode instead of `r`, it will overwrite the content.\n",
    "\n",
    "Also, unpickling objects found on the internet is not secure: it can execute arbitrary code on your machine. Use it only for things you trust and things you saved yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9dd11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, 'rb') as f_in: \n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5806ef9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DictVectorizer(sparse=False), LogisticRegression(max_iter=3000))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ca6a1e-9c3a-401b-a7fe-86699819b859",
   "metadata": {},
   "source": [
    "Notice that we did not import scikit-learn but we need to have scikit-learn installed on our computer for this to work. Otherwise, it will complain not knowing what this is (referring to these classes) when we try to load the pickle file and this is because scikit-learn is not installed on our computer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16d96d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = {\n",
    "    'gender': 'female',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'yes',\n",
    "    'dependents': 'no',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'month-to-month',\n",
    "    'paperlessbilling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': 29.85\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17ad51a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,\n",
       "         0.  ,  1.  ,  0.  ,  0.  , 29.85,  0.  ,  1.  ,  0.  ,  0.  ,\n",
       "         0.  ,  1.  ,  1.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,\n",
       "         0.  ,  0.  ,  1.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,\n",
       "         0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  , 29.85]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn this customer into feature matrix\n",
    "X = dv.transform([customer])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22167f4b-607b-4223-90c7-506df5f87ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37255464, 0.62744536]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4934ac59-84c3-478f-8fb6-16bfc52cd8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62744536])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0758291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6274453618230489)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the probability that this particular customer is going to churn\n",
    "y_pred = model.predict_proba(X)[0, 1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79c7d951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: {'gender': 'female', 'seniorcitizen': 0, 'partner': 'yes', 'dependents': 'no', 'phoneservice': 'no', 'multiplelines': 'no_phone_service', 'internetservice': 'dsl', 'onlinesecurity': 'no', 'onlinebackup': 'yes', 'deviceprotection': 'no', 'techsupport': 'no', 'streamingtv': 'no', 'streamingmovies': 'no', 'contract': 'month-to-month', 'paperlessbilling': 'yes', 'paymentmethod': 'electronic_check', 'tenure': 1, 'monthlycharges': 29.85, 'totalcharges': 29.85}\n",
      "output: 0.6274453618230489\n"
     ]
    }
   ],
   "source": [
    "print('input:', customer)\n",
    "print('output:', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebf1806-562e-47a1-921c-a2f2ed6f8041",
   "metadata": {},
   "source": [
    "This way, we can load the model and apply it to the customer we specified in the script. \n",
    "\n",
    "Of course, we aren't going to manually put the information about customers in the script. In the next section, we'll cover a more practical approach where we will be putting the model into a web service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "703ab71a-35fd-438c-8ade-536fc232d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to train.py and predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1869a7dd-e75c-46f6-91fb-118c0a41e764",
   "metadata": {},
   "source": [
    "## 5.3 Web services: introduction to Flask\n",
    "The easiest way to implement a web service in Python is to use Flask. It's quite light-weight, requires little code to get started, and hides most of the complexity of dealing with HTTP requests and responses. \n",
    "\n",
    "Before we put our model inside a web service, let's cover the basics of using Flask. For that, we'll create a simple function and make it available as a web service. \n",
    "* Writing a simple ping/pong app\n",
    "* Querying it with `curl` and browser\n",
    "\n",
    "Web service:\n",
    "- A web service is a method used to communicate between electronic devices.\n",
    "- Below are some methods in web services that we can use to satisfy our problems:\n",
    "    - **GET:** A method used to retrieve files. For example, when we are searching for a cat image in google, we're actually requesting cat images with GET method.\n",
    "    - **POST:** The second most common method used in web services. It enables sending data to a server to create or update a resource. For example, during a sign up process, we are submitting our name, username, password, etc. to a server that is using a web service. (Note that there is no specification on where the data goes)\n",
    "    - **PUT:** Same as POST, but we are specifying where the data is going to.\n",
    "    - **DELETE:** A method that is used to delete some data from the server.\n",
    "- For more information, google \"HTTP methods\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e89ad399-18da-4e8f-8013-662f4b989bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to ping.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15eb89-c31b-4f19-851b-f2c6f804e311",
   "metadata": {},
   "source": [
    "This is the content in the `ping.py` file\n",
    "```python\n",
    "# ping.py\n",
    "def ping():\n",
    "    return \"PONG\"\n",
    "```\n",
    "\n",
    "Run the program by executing this command on the terminal\n",
    "```bash\n",
    "ipython\n",
    "```\n",
    "Then, enter the following code in the Interactive Python mode:\n",
    "```python\n",
    "import ping\n",
    "\n",
    "ping.ping()\n",
    "```\n",
    "\n",
    "Now, we want to turn this function into a web service and we'll use Flask for that\n",
    "```bash\n",
    "pip install flask\n",
    "```\n",
    "\n",
    "Decorator is just a way to add some extra functionality to our functions and this extra functionality that we're going to add will allow us to turn this function into a web service.\n",
    "\n",
    "By putting `@app.route` on top of the function definition, we assign the `/ping` address of the web service to the `ping` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170d764b-973d-47e1-aaaa-195b306823f4",
   "metadata": {},
   "source": [
    "```python\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask('ping')  # Give an identity to your web service\n",
    "\n",
    "# Use decorator to add Flask's functionality to our function\n",
    "@app.route('/ping', methods=['GET'])  \n",
    "def ping():\n",
    "    return \"PONG\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the code in local machine with debugging mode true and port 9696\n",
    "    app.run(debug=True, host='0.0.0.0', port=9696)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a87e28-6d3e-4181-b25b-715cb611a37a",
   "metadata": {},
   "source": [
    "The `run` method of `app` starts the service. We specify three parameters:\n",
    "- `debug=True`: Restarts our application automatically when there are changes in the code.\n",
    "- `host='0.0.0.0'`: Makes the web service public; otherwise, it won't be possible to reach it when it's hosted on a remote machine (e.g., in AWS).\n",
    "- `port=9696`: The port that we use to access the application.\n",
    "\n",
    "To start our service, execute this on the terminal:\n",
    "```bash\n",
    "python ping.py\n",
    "```\n",
    "\n",
    "`curl` is a special command line utility for communicating with web services. \n",
    "\n",
    "You can use `0.0.0.0` for localhost and then specify the port `9696`.\n",
    "\n",
    "```bash\n",
    "curl http://0.0.0.0:9696/ping\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1a24030-6c33-4e8e-b3e4-548eeb8e58c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PONG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100     4  100     4    0     0   1646      0 --:--:-- --:--:-- --:--:--  2000\n"
     ]
    }
   ],
   "source": [
    "!curl http://127.0.0.1:9696/ping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19b0fd12-2a25-4ae1-b16e-df3183c6938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PONG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100     4  100     4    0     0     19      0 --:--:-- --:--:-- --:--:--    19\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:9696/ping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace708d3-74fc-4b9a-9311-2597051a74e4",
   "metadata": {},
   "source": [
    "## 5.4 Serving the churn model with Flask\n",
    "In this session, we talked about implementing the functionality of prediction to our churn web service and how to make it usable in development environment. \n",
    "* Wrapping the predict script into a Flask app\n",
    "* Querying it with `requests` \n",
    "* Preparing for production: gunicorn\n",
    "* Running it on Windows with waitress\n",
    "\n",
    "There nay be situation where the campaign service is written in some other language, or a different team might be in charge of this project, which means we won't have the control we need to modify the code of the campaign service to load the model, and score the customers right in the service.\n",
    "\n",
    "The typical solution for this problem is putting a model inside a web service--a small service (a microservice) that only takes care of scoring customers. \n",
    "\n",
    "So, we need to create a churn service--a service in Python that will serve the churn model. Given the features of a customer, it will respond with the probability of churn for this customer. For each customer, the campaign service will ask the churn service for the probability of churn, and if it's high enough, then we send a promotional email.\n",
    "\n",
    "This gives us another advantage: separation of concerns. If the model is created by data scientists, then they can take ownership of the service and maintain it, while the other team takes care of the campaign service. \n",
    "\n",
    "To load the saved model, we use the code below:\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "with open('churn-model.bin', 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)\n",
    "```\n",
    "\n",
    "To predict a value for a customer, we need a function like below:\n",
    "```python\n",
    "def predict_single(customer, dv, model):\n",
    "    # Apply the one-hot encoding feature to the customer data\n",
    "    X = dv.transform([customer]) \n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    return y_pred[0]\n",
    "```\n",
    "\n",
    "At last, we create the final function used for implementing the web service:\n",
    "```python\n",
    "# To send the customer information, we need to post its data\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Web services work best with JSON format\n",
    "    customer = request.get_json()  # Access the content of a POST request\n",
    "\n",
    "    prediction = predict_single(customer, dv, model)\n",
    "    churn = prediction >= 0.5\n",
    "\n",
    "    result = {\n",
    "        # Cast numpy float type to Python native float type\n",
    "        'churn_probability': float(prediction), \n",
    "        'churn': bool(churn), # Cast the value using bool method\n",
    "    }\n",
    "    # Send back the result in JSON format to the user\n",
    "    return jsonify(result) \n",
    "```\n",
    "\n",
    "To get a response, we post customer data as `json`:\n",
    "```python\n",
    "# A new customer information\n",
    "customer = {\n",
    "    'gender': 'female',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'yes',\n",
    "    'dependents': 'no',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'month-to-month',\n",
    "    'paperlessbilling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': 29.85\n",
    "}\n",
    "\n",
    "import requests # We need the requests library to use the POST method\n",
    "\n",
    "url = 'http://localhost:9696/predict' # The route we made for prediction\n",
    "# Post the customer information in JSON format\n",
    "response = requests.post(url, json=customer)\n",
    "result = response.json() # Get the server response\n",
    "print(result)\n",
    "```\n",
    "\n",
    "To fix the \"This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\" warning:\n",
    "* Consider creating a WSGI server using gunicorn. Use the command `pip install gunicorn` to install it. To run the WSGI server, simply execute the command `gunicorn --bind 0.0.0.0:9696 churn:app`. Note that in **churn:app**, 'churn' is the name we set for the file containing the code `app = Flask('churn')` (e.g., churn.py). You may need to change it to match the name of your Flask app file. \n",
    "* Windows users need to use an alternative library, `waitress`, because the windows system do not support some dependencies of the gunicorn library. Use the command `pip install waitress` to install it.\n",
    "* To run the waitress WSGI server, use the command `waitress-serve --listen=0.0.0.0:9696 churn:app`. \n",
    "* To test it, you can run the code above and the result will be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163bfa7d",
   "metadata": {},
   "source": [
    "`05-predict-test.ipynb`\n",
    "\n",
    "#### Making requests\n",
    "\n",
    "Testing this code is a bit more difficult than previously. We need to use POST requests and include the customer we want to score in the body of the request. The simplest way of doing this is to use the requests library in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "934c7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68bf9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The URL where the service lives\n",
    "url = 'http://localhost:9696/predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "506e09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = {\n",
    "    'gender': 'female',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'yes',\n",
    "    'dependents': 'no',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'two_year',\n",
    "    'paperlessbilling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': 29.85\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cfa63a96-ee23-4e7d-81e0-6f5feff4cf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': 'female',\n",
       " 'seniorcitizen': 0,\n",
       " 'partner': 'yes',\n",
       " 'dependents': 'no',\n",
       " 'phoneservice': 'no',\n",
       " 'multiplelines': 'no_phone_service',\n",
       " 'internetservice': 'dsl',\n",
       " 'onlinesecurity': 'no',\n",
       " 'onlinebackup': 'yes',\n",
       " 'deviceprotection': 'no',\n",
       " 'techsupport': 'no',\n",
       " 'streamingtv': 'no',\n",
       " 'streamingmovies': 'no',\n",
       " 'contract': 'two_year',\n",
       " 'paperlessbilling': 'yes',\n",
       " 'paymentmethod': 'electronic_check',\n",
       " 'tenure': 1,\n",
       " 'monthlycharges': 29.85,\n",
       " 'totalcharges': 29.85}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c98d0-b7bb-400c-8563-9a94368c6bc5",
   "metadata": {},
   "source": [
    "`requests.post(url, json=customer)` will give us a TypeError: Object of type bool_ is not JSON serializable. \n",
    "\n",
    "We need to cast both `y_pred` and `churn` variables in `predict.py` into their respective Python datatypes because they're currently under the numpy datatypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86c45ac1-1c0d-4ac7-8652-5f60f1e82676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(url, json=customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "72f4135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sends the customer (as JSON) in the POST request and parses the response as JSON\n",
    "response = requests.post(url, json=customer).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4b2c002a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'churn': False, 'churn_probability': 0.29549015063752093}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0faf6209-1871-4d32-9182-1f6352c9669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response['churn'] == True:\n",
    "    # 'asdx-123d' refers to the customer_id\n",
    "    print('sending promo email to', 'asdx-123d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b06a438-6754-4dec-9830-451333260b4e",
   "metadata": {},
   "source": [
    "If the campaign service used Python, this is exactly how it could communicate with the churn service and decide who should get promotional emails. \n",
    "\n",
    "Note: Some tools like [Postman](https://www.postman.com/), make it easier to test web services. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cc4fd976-a1b0-4b31-a84f-5beb58321c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': 'female',\n",
       " 'seniorcitizen': 0,\n",
       " 'partner': 'yes',\n",
       " 'dependents': 'no',\n",
       " 'phoneservice': 'no',\n",
       " 'multiplelines': 'no_phone_service',\n",
       " 'internetservice': 'dsl',\n",
       " 'onlinesecurity': 'no',\n",
       " 'onlinebackup': 'yes',\n",
       " 'deviceprotection': 'no',\n",
       " 'techsupport': 'no',\n",
       " 'streamingtv': 'no',\n",
       " 'streamingmovies': 'no',\n",
       " 'contract': 'month-to-month',\n",
       " 'paperlessbilling': 'yes',\n",
       " 'paymentmethod': 'electronic_check',\n",
       " 'tenure': 1,\n",
       " 'monthlycharges': 29.85,\n",
       " 'totalcharges': 29.85}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer = {\n",
    "    'gender': 'female',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'yes',\n",
    "    'dependents': 'no',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'month-to-month',\n",
    "    'paperlessbilling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': 29.85\n",
    "}\n",
    "customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d43a9d6d-87a8-4377-8e06-2963adc632ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'churn': True, 'churn_probability': 0.6274453618230489}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.post(url, json=customer).json()\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8db38caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending email to xyz-123\n"
     ]
    }
   ],
   "source": [
    "if response['churn']:\n",
    "    # 'xyz-123' refers to the customer_id\n",
    "    print('sending email to', 'xyz-123')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e53827-fd3a-4f6a-969a-65b94d7a284f",
   "metadata": {},
   "source": [
    "WSGI stands for *web server gateway interface*, which is a specification describing how Python applications should handle HTTP requests.\n",
    "\n",
    "Let's address the warning by installing a production WSGI server. We have multiple options in Python: install Gunicorn or Waitress.\n",
    "\n",
    "We'll use Waitress because Gunicorn doesn't work on Windows: it relies on features specific to Linux and Unix (which includes MacOS). Later, we will use Docker, which will solve this problem--it runs Linux inside a container. \n",
    "```bash\n",
    "pip install waitress\n",
    "```\n",
    "\n",
    "To use it\n",
    "```bash\n",
    "waitress-serve --listen=0.0.0.0:9696 predict:app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94336d-ec83-4413-9218-10283ca2632b",
   "metadata": {},
   "source": [
    "Refer to `predict-test.py`\n",
    "\n",
    "Execute the script\n",
    "```bash\n",
    "python predict-test.py\n",
    "```\n",
    "\n",
    "Unlike the Flask built-in web server, Gunicorn or Waitress is ready for production, so it will not have any problems under load when we start using it. \n",
    "\n",
    "We see that it is able to communicate with Waitress and get back a successful response. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51f01f-b2c4-43ec-ad6a-7ec9f4b20ba1",
   "metadata": {},
   "source": [
    "## 5.5 Python virtual environment: Pipenv\n",
    "\n",
    "* Dependency and environment management\n",
    "* Why we need virtual environment\n",
    "* Installing Pipenv\n",
    "* Installing libraries with Pipenv\n",
    "* Running things with Pipenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f351f-ab62-44cb-af0d-a53bd633dbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57d989c4-6842-4874-9ed4-0472dd28f403",
   "metadata": {},
   "source": [
    "## 5.6 Environment management: Docker\n",
    "\n",
    "* Why we need Docker\n",
    "* Running a Python image with docker\n",
    "* Dockerfile\n",
    "* Building a docker image\n",
    "* Running a docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab40ad-8053-457b-ac22-ce2dbc0760d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f12b82d-0b35-4b58-8d78-290b118d778e",
   "metadata": {},
   "source": [
    "## 5.7 Deployment to the cloud: AWS Elastic Beanstalk (optional)\n",
    "\n",
    "* Installing the eb cli\n",
    "* Running eb locally\n",
    "* Deploying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb71d87-5649-4d08-bb0b-8fc35903d821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a977863-77d4-4189-80da-23c1b08964e7",
   "metadata": {},
   "source": [
    "## 5.8 Summary\n",
    "\n",
    "* Save models with picke\n",
    "* Use Flask to turn the model into a web service\n",
    "* Use a dependency & env manager\n",
    "* Package it in Docker\n",
    "* Deploy to the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6a2c2-df4e-4313-b49f-bdde6bafe60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "245577bf-2a93-4049-ab9c-b63a8fea126d",
   "metadata": {},
   "source": [
    "## 5.9 Explore more\n",
    "\n",
    "* Flask is not the only framework for creating web services. Try others, e.g. FastAPI\n",
    "* Experiment with other ways of managing environment, e.g. virtual env, conda, poetry.\n",
    "* Explore other ways of deploying web services, e.g. GCP, Azure, Heroku, Python Anywhere, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c76ba02-1bd3-4fc1-901d-9136ac77a57a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
