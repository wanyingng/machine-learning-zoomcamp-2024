{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2dc2fed-2cc9-4bf3-8adb-274c184d8061",
   "metadata": {},
   "source": [
    "# 5. Deploying Machine Learning models \n",
    "\n",
    "We'll use the same model we trained and evaluated previously - the churn prediction model. Now we'll deploy it as a web service.\n",
    "\n",
    "## 5.1 Intro / Session overview\n",
    "We need to put the model that lives in our Jupyter Notebook into production, so other services can use the model to make decisions based on the output of our model.\n",
    "\n",
    "Suppose we have a service for running marketing campaigns. For each customer, it needs to determine the probability of churn, and if it's high enough, it will send a promotional email with discounts. This service needs to use our model to decide whether it should send an email. \n",
    "\n",
    "What we will cover this week: \n",
    "* Saving models with Pickle\n",
    "* Serving models with Flask\n",
    "* Managing dependencies with Pipenv\n",
    "* Making the service self-contained with Docker\n",
    "* Deploying it to the cloud using AWS Elastic Beanstalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ff7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b9c8d1-3b63-4fc2-828c-7878dd6e9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-03-churn-prediction/WA_Fn-UseC_-Telco-Customer-Churn.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ee3ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data-week-3.csv')\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "\n",
    "for c in categorical_columns:\n",
    "    df[c] = df[c].str.lower().str.replace(' ', '_')\n",
    "\n",
    "df.totalcharges = pd.to_numeric(df.totalcharges, errors='coerce')\n",
    "df.totalcharges = df.totalcharges.fillna(0)\n",
    "\n",
    "df.churn = (df.churn == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b1903b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4132a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "\n",
    "categorical = [\n",
    "    'gender',\n",
    "    'seniorcitizen',\n",
    "    'partner',\n",
    "    'dependents',\n",
    "    'phoneservice',\n",
    "    'multiplelines',\n",
    "    'internetservice',\n",
    "    'onlinesecurity',\n",
    "    'onlinebackup',\n",
    "    'deviceprotection',\n",
    "    'techsupport',\n",
    "    'streamingtv',\n",
    "    'streamingmovies',\n",
    "    'contract',\n",
    "    'paperlessbilling',\n",
    "    'paymentmethod',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92708443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(C=C, max_iter=3000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ac302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b01b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.0\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce936aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0 0.842 +- 0.007\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train.churn.values\n",
    "    y_val = df_val.churn.values\n",
    "\n",
    "    dv, model = train(df_train, y_train, C=C)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "\n",
    "print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f72b194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.8443806862337213),\n",
       " np.float64(0.8449563799496754),\n",
       " np.float64(0.83351796106763),\n",
       " np.float64(0.8347649005563726),\n",
       " np.float64(0.8517892441404411)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03e81326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8583598751990639)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model = train(df_full_train, df_full_train.churn.values, C=1.0)\n",
    "y_pred = predict(df_test, dv, model)\n",
    "\n",
    "y_test = df_test.churn.values\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f0681-8cd1-4da2-9736-17579c797fcf",
   "metadata": {},
   "source": [
    "## 5.2 Saving and loading the model\n",
    "\n",
    "* Saving the model to pickle\n",
    "* Loading the model from pickle\n",
    "* Turning our notebook into a Python script\n",
    "\n",
    "To be able to use it outside of our notebook, we need to save it, and then later, another process can load and use it.\n",
    "\n",
    "Pickle is a serialization/deserialization module that's already built into Python: using it, we can save an arbitrary Python object (with a few exceptions) to a file. Once we have a file, we can load the model from there in a different process.\n",
    "\n",
    "Install the library with the command `pip install pickle-mixin` if you don't have it.\n",
    "\n",
    "To save the model, we first import the `pickle` module, and then use the `dump` function:\n",
    "  ```python\n",
    "  import pickle\n",
    "\n",
    "  with open('model.bin', 'wb') as f_out:  # 'wb' means write binary\n",
    "      pickle.dump((dict_vectorizer, model), f_out)\n",
    "  ```\n",
    "  \n",
    "To use the model, we need to open the binary file we saved and load the model using the `load` function.\n",
    "\n",
    "  ```python\n",
    "  import pickle\n",
    "\n",
    "  with open('model.bin', 'rb') as f_in:  # 'rb' means read binary\n",
    "      # Note: Never open a binary file from an untrusted source!\n",
    "      dict_vectorizer, model = pickle.load(f_in)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e8c00a-1a6c-4a35-9c18-062991be2eba",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a452f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4d16a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f'model_C={C}.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9533d28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_C=1.0.bin'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f07f38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to the file in binary\n",
    "f_out = open(output_file, 'wb') \n",
    "pickle.dump((dv, model), f_out)\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8887621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lh *.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f85192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'wb') as f_out: \n",
    "    pickle.dump((dv, model), f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d8a59e",
   "metadata": {},
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fe3b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "007e9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'model_C=1.0.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b876b1ab-0e07-48ba-95a2-c057398cdd3a",
   "metadata": {},
   "source": [
    "Be careful when specifying the mode. Accidentally specifying an incorrect mode may result in data loss: if you open an existing file with the `w` mode instead of `r`, it will overwrite the content.\n",
    "\n",
    "Also, unpickling objects found on the internet is not secure: it can execute arbitrary code on you machine. Use it only for things you trust and things you saved yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9dd11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, 'rb') as f_in: \n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5806ef9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DictVectorizer(sparse=False), LogisticRegression(max_iter=3000))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ca6a1e-9c3a-401b-a7fe-86699819b859",
   "metadata": {},
   "source": [
    "Notice that we did not import scikit-learn but we need to have scikit-learn installed on our computer for this to work. Otherwise, it will complain not knowing what this is (referring to these classes) when we try to load the pickle file and this is because scikit-learn is not installed on our computer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16d96d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = {\n",
    "    'gender': 'female',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'yes',\n",
    "    'dependents': 'no',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'month-to-month',\n",
    "    'paperlessbilling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': 29.85\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17ad51a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,\n",
       "         0.  ,  1.  ,  0.  ,  0.  , 29.85,  0.  ,  1.  ,  0.  ,  0.  ,\n",
       "         0.  ,  1.  ,  1.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  1.  ,\n",
       "         0.  ,  0.  ,  1.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,\n",
       "         0.  ,  1.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,  1.  , 29.85]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn this customer into feature matrix\n",
    "X = dv.transform([customer])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22167f4b-607b-4223-90c7-506df5f87ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37255464, 0.62744536]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4934ac59-84c3-478f-8fb6-16bfc52cd8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62744536])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0758291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6274453618230489)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the probability that this particular customer is going to churn\n",
    "y_pred = model.predict_proba(X)[0, 1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79c7d951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: {'gender': 'female', 'seniorcitizen': 0, 'partner': 'yes', 'dependents': 'no', 'phoneservice': 'no', 'multiplelines': 'no_phone_service', 'internetservice': 'dsl', 'onlinesecurity': 'no', 'onlinebackup': 'yes', 'deviceprotection': 'no', 'techsupport': 'no', 'streamingtv': 'no', 'streamingmovies': 'no', 'contract': 'month-to-month', 'paperlessbilling': 'yes', 'paymentmethod': 'electronic_check', 'tenure': 1, 'monthlycharges': 29.85, 'totalcharges': 29.85}\n",
      "output: 0.6274453618230489\n"
     ]
    }
   ],
   "source": [
    "print('input:', customer)\n",
    "print('output:', y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebf1806-562e-47a1-921c-a2f2ed6f8041",
   "metadata": {},
   "source": [
    "This way, we can load the model and apply it to the customer we specified in the script. \n",
    "\n",
    "Of course, we aren't going to manually put the information about customers in the script. In the next section, we'll cover a more practical approach where we will be putting the model into a web service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "703ab71a-35fd-438c-8ade-536fc232d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to train.py and predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1869a7dd-e75c-46f6-91fb-118c0a41e764",
   "metadata": {},
   "source": [
    "## 5.3 Web services: introduction to Flask\n",
    "The easiest way to implement a web service in Python is to use Flask. It's quite light-weight, requires little code to get started, and hides most of the complexity of dealing with HTTP requests and responses. \n",
    "\n",
    "Before we put our model inside a web service, let's cover the basics of using Flask. For that, we'll create a simple function and make it available as a web service. \n",
    "* Writing a simple ping/pong app\n",
    "* Querying it with `curl` and browser\n",
    "\n",
    "Web service:\n",
    "- A web service is a method used to communicate between electronic devices.\n",
    "- Below are some methods in web services that we can use to satisfy our problems:\n",
    "    - **GET:** A method used to retrieve files. For example, when we are searching for a cat image in google, we're actually requesting cat images with GET method.\n",
    "    - **POST:** The second most common method used in web services. It enables sending data to a server to create or update a resource. For example, during a sign up process, we are submitting our name, username, password, etc. to a server that is using a web service. (Note that there is no specification on where the data goes)\n",
    "    - **PUT:** Same as POST, but we are specifying where the data is going to.\n",
    "    - **DELETE:** A method that is used to delete some data from the server.\n",
    "- For more information, google \"HTTP methods\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e89ad399-18da-4e8f-8013-662f4b989bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to ping.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15eb89-c31b-4f19-851b-f2c6f804e311",
   "metadata": {},
   "source": [
    "This is the content in the `ping.py` file\n",
    "```python\n",
    "# ping.py\n",
    "def ping():\n",
    "    return \"PONG\"\n",
    "```\n",
    "\n",
    "Run the program by executing this command on the terminal\n",
    "```bash\n",
    "ipython\n",
    "```\n",
    "Then, enter the following code in the Interactive Python mode:\n",
    "```python\n",
    "import ping\n",
    "\n",
    "ping.ping()\n",
    "```\n",
    "\n",
    "Now, we want to turn this function into a web service and we'll use Flask for that\n",
    "```bash\n",
    "pip install flask\n",
    "```\n",
    "\n",
    "Decorator is just a way to add some extra functionality to our functions and this extra functionality that we're going to add will allow us to turn this function into a web service.\n",
    "\n",
    "By putting `@app.route` on top of the function definition, we assign the `/ping` address of the web service to the `ping` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170d764b-973d-47e1-aaaa-195b306823f4",
   "metadata": {},
   "source": [
    "```python\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask('ping')  # Give an identity to your web service\n",
    "\n",
    "# Use decorator to add Flask's functionality to our function\n",
    "@app.route('/ping', methods=['GET'])  \n",
    "def ping():\n",
    "    return \"PONG\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the code in local machine with debugging mode true and port 9696\n",
    "    app.run(debug=True, host='0.0.0.0', port=9696)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a87e28-6d3e-4181-b25b-715cb611a37a",
   "metadata": {},
   "source": [
    "The `run` method of `app` starts the service. We specify three parameters:\n",
    "- `debug=True`: Restarts our application automatically when there are changes in the code.\n",
    "- `host='0.0.0.0'`: Makes the web service public; otherwise, it won't be possible to reach it when it's hosted on a remote machine (e.g., in AWS).\n",
    "- `port=9696`: The port that we use to access the application.\n",
    "\n",
    "To start our service, execute this on the terminal:\n",
    "```bash\n",
    "python ping.py\n",
    "```\n",
    "\n",
    "`curl` is a special command line utility for communicating with web services. \n",
    "\n",
    "You can use `0.0.0.0` for localhost and then specify the port `9696`.\n",
    "\n",
    "```bash\n",
    "curl http://0.0.0.0:9696/ping\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1a24030-6c33-4e8e-b3e4-548eeb8e58c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PONG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100     4  100     4    0     0    351      0 --:--:-- --:--:-- --:--:--   363\n"
     ]
    }
   ],
   "source": [
    "!curl http://127.0.0.1:9696/ping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19b0fd12-2a25-4ae1-b16e-df3183c6938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PONG"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100     4  100     4    0     0     19      0 --:--:-- --:--:-- --:--:--    19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:9696/ping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace708d3-74fc-4b9a-9311-2597051a74e4",
   "metadata": {},
   "source": [
    "## 5.4 Serving the churn model with Flask\n",
    "In this session, we talked about implementing the functionality of prediction to our churn web service and how to make it usable in development environment. \n",
    "* Wrapping the predict script into a Flask app\n",
    "* Querying it with `requests` \n",
    "* Preparing for production: gunicorn\n",
    "* Running it on Windows with waitress\n",
    "\n",
    "To load the saved model, we use the code below:\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "with open('churn-model.bin', 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)\n",
    "```\n",
    "\n",
    "To predict a value for a customer, we need a function like below:\n",
    "```python\n",
    "def predict_single(customer, dv, model):\n",
    "    # Apply the one-hot encoding feature to the customer data\n",
    "    X = dv.transform([customer]) \n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    return y_pred[0]\n",
    "```\n",
    "\n",
    "At last, we create the final function used for implementing the web service:\n",
    "```python\n",
    "# To send the customer information, we need to post its data\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Web services work best with JSON format\n",
    "    customer = request.get_json()  # Access the body of JSON\n",
    "\n",
    "    prediction = predict_single(customer, dv, model)\n",
    "    churn = prediction >= 0.5\n",
    "\n",
    "    result = {\n",
    "        # Cast numpy float type to Python native float type\n",
    "        'churn_probability': float(prediction), \n",
    "        'churn': bool(churn), # Cast the value using bool method\n",
    "    }\n",
    "    # Send back the result in JSON format to the user\n",
    "    return jsonify(result) \n",
    "```\n",
    "\n",
    "To get a response, we post customer data as `json`:\n",
    "```python\n",
    "# A new customer information\n",
    "customer = {\n",
    "    'gender': 'female',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'yes',\n",
    "    'dependents': 'no',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'month-to-month',\n",
    "    'paperlessbilling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': 29.85\n",
    "}\n",
    "\n",
    "import requests # We need the requests library to use the POST method\n",
    "\n",
    "url = 'http://localhost:9696/predict' # The route we made for prediction\n",
    "# Post the customer information in JSON format\n",
    "response = requests.post(url, json=customer)\n",
    "result = response.json() # Get the server response\n",
    "print(result)\n",
    "```\n",
    "\n",
    "To fix the \"This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\" warning:\n",
    "* Consider creating a WSGI server using gunicorn. Use the command `pip install gunicorn` to install it. To run the WSGI server, simply execute the command `gunicorn --bind 0.0.0.0:9696 churn:app`. Note that in **churn:app**, 'churn' is the name we set for the file containing the code `app = Flask('churn')` (e.g., churn.py). You may need to change it to match the name of your Flask app file. \n",
    "* Windows users need to use an alternative library, `waitress`, because the windows system do not support some dependencies of the gunicorn library. Use the command `pip install waitress` to install it.\n",
    "* To run the waitress WSGI server, use the command `waitress-serve --listen=0.0.0.0:9696 churn:app`. \n",
    "* To test it, you can run the code above and the result will be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163bfa7d",
   "metadata": {},
   "source": [
    "Making requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934c7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bf9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://localhost:9696/predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = {\n",
    "    'gender': 'female',\n",
    "    'seniorcitizen': 0,\n",
    "    'partner': 'yes',\n",
    "    'dependents': 'no',\n",
    "    'phoneservice': 'no',\n",
    "    'multiplelines': 'no_phone_service',\n",
    "    'internetservice': 'dsl',\n",
    "    'onlinesecurity': 'no',\n",
    "    'onlinebackup': 'yes',\n",
    "    'deviceprotection': 'no',\n",
    "    'techsupport': 'no',\n",
    "    'streamingtv': 'no',\n",
    "    'streamingmovies': 'no',\n",
    "    'contract': 'two_year',\n",
    "    'paperlessbilling': 'yes',\n",
    "    'paymentmethod': 'electronic_check',\n",
    "    'tenure': 1,\n",
    "    'monthlycharges': 29.85,\n",
    "    'totalcharges': 29.85\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url, json=customer).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db38caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response['churn']:\n",
    "    print('sending email to', 'asdx-123d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9a70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015cf49-f19e-494e-ad95-e47ea43c72ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c51f01f-b2c4-43ec-ad6a-7ec9f4b20ba1",
   "metadata": {},
   "source": [
    "## 5.5 Python virtual environment: Pipenv\n",
    "\n",
    "* Dependency and environment management\n",
    "* Why we need virtual environment\n",
    "* Installing Pipenv\n",
    "* Installing libraries with Pipenv\n",
    "* Running things with Pipenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f351f-ab62-44cb-af0d-a53bd633dbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57d989c4-6842-4874-9ed4-0472dd28f403",
   "metadata": {},
   "source": [
    "## 5.6 Environment management: Docker\n",
    "\n",
    "* Why we need Docker\n",
    "* Running a Python image with docker\n",
    "* Dockerfile\n",
    "* Building a docker image\n",
    "* Running a docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab40ad-8053-457b-ac22-ce2dbc0760d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f12b82d-0b35-4b58-8d78-290b118d778e",
   "metadata": {},
   "source": [
    "## 5.7 Deployment to the cloud: AWS Elastic Beanstalk (optional)\n",
    "\n",
    "* Installing the eb cli\n",
    "* Running eb locally\n",
    "* Deploying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb71d87-5649-4d08-bb0b-8fc35903d821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a977863-77d4-4189-80da-23c1b08964e7",
   "metadata": {},
   "source": [
    "## 5.8 Summary\n",
    "\n",
    "* Save models with picke\n",
    "* Use Flask to turn the model into a web service\n",
    "* Use a dependency & env manager\n",
    "* Package it in Docker\n",
    "* Deploy to the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6a2c2-df4e-4313-b49f-bdde6bafe60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "245577bf-2a93-4049-ab9c-b63a8fea126d",
   "metadata": {},
   "source": [
    "## 5.9 Explore more\n",
    "\n",
    "* Flask is not the only framework for creating web services. Try others, e.g. FastAPI\n",
    "* Experiment with other ways of managing environment, e.g. virtual env, conda, poetry.\n",
    "* Explore other ways of deploying web services, e.g. GCP, Azure, Heroku, Python Anywhere, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c76ba02-1bd3-4fc1-901d-9136ac77a57a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
